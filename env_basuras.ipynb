{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9c82bb",
   "metadata": {},
   "source": [
    "# Entorno Recogida de Basuras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0152da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch\n",
    "import networkx as nx \n",
    "import osmnx as ox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d297aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecogidaBasurasEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, nodos_indice, aristas_indice, capacidad_camion = 120.0, steps_maximo = 2500, mascara = True): # añadida máscara para indicar si el agente solo elije las acciones permitidas o pueda elegir todas las acciones posibles (incluso las prohibidas)\n",
    "        super().__init__()\n",
    "        self.nodos_indice = nodos_indice\n",
    "        self.aristas_indice = aristas_indice\n",
    "        self.capacidad_camion = capacidad_camion\n",
    "        self.carga_camion = 0\n",
    "        self.steps_maximo = steps_maximo\n",
    "        self.steps = 0\n",
    "        self.tiempo_total = 0 #s\n",
    "        self.mascara = mascara\n",
    "\n",
    "        self.nodo_inicial = 103 #Entrada pueblo.\n",
    "        self.nodo_actual = self.nodo_inicial\n",
    "        self.nodo_anterior = None\n",
    "\n",
    "        self.adjacencia = self._nodos_adjacentes()  \n",
    "\n",
    "        # Espacio de acciones \n",
    "        self.action_space = spaces.Dict({\n",
    "            \"tipo\" : spaces.Discrete(2), # 1 recoger basura, 0 moverse\n",
    "            \"destino\" : spaces.Discrete(len(nodos_indice)) \n",
    "        })\n",
    "\n",
    "        # Espacio de observaciones\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"posicion_camion\" : spaces.Discrete(len(nodos_indice)),\n",
    "            \"llenado_camion\" : spaces.Box(0.0, self.capacidad_camion, shape=()),\n",
    "            \"contenedor\" : spaces.Discrete(2),\n",
    "            \"llenado_contenedor\" : spaces.Box(0.0, 1.0, shape=()) # Nivel lleando contenedores normalizado\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "    # Creación dle diccionario de nodos accesibles a partir de uno \n",
    "    def _nodos_adjacentes(self):  \n",
    "        adj = {nid: [] for nid in self.nodos_indice.keys()}\n",
    "        for _, data in self.aristas_indice.items():\n",
    "            u = data[\"desde\"]\n",
    "            v = data[\"hasta\"]\n",
    "            adj[u].append(v)\n",
    "        return adj\n",
    "    \n",
    "\n",
    "\n",
    "    def reset(self, seed = 123, options = None):  # Seed 123 para desarrollo, None para entrenamineto agente, varias seeds fijas para fase final\n",
    "        super().reset(seed = seed)\n",
    "        self.nodo_actual = self.nodo_inicial\n",
    "        self.carga_camion = 0.0\n",
    "        self.steps = 0\n",
    "        self.tiempo_total = 0\n",
    "\n",
    "        # Reinicio de los nodos: rellenado de contenedores e incialización posicion inicial camión \n",
    "        for indice, nodo in self.nodos_indice.items():\n",
    "            nodo[\"llenado\"] = 0.5 if nodo[\"contenedor\"] == 1 else 0 #Futuro, np.random(0.0, 0.90)\n",
    "            nodo[\"llenado_camion\"] = 0.0\n",
    "            nodo[\"posicion_camion\"] = 1 if indice == self.nodo_inicial else 0\n",
    "\n",
    "        # Inicializacion nuevas condiciones inciales tráfico\n",
    "\n",
    "        obs = self._obtener_observacion()\n",
    "        info = {\"mascara\": self._mascara_acciones()} if self.mascara else {}\n",
    "        return obs, info\n",
    "    \n",
    "\n",
    "\n",
    "    def _obtener_observacion(self):\n",
    "        nodo = self.nodos_indice[self.nodo_actual]\n",
    "\n",
    "        obs_simple = {\n",
    "            \"posicion_camion\": self.nodo_actual,\n",
    "            \"llenado_camion\": float(min(1.0, self.carga_camion / self.capacidad_camion)),\n",
    "            \"contenedor\": int(nodo[\"contenedor\"]),\n",
    "            \"llenado_contenedor\": float(nodo[\"llenado\"])\n",
    "        }\n",
    "\n",
    "        \n",
    "        obs_grafo = {\n",
    "            \"nodos_indice\" : self.nodos_indice,\n",
    "            \"aristas_indice\" : self.aristas_indice \n",
    "        }\n",
    "\n",
    "        return {\"simple\" : obs_simple, \"grafo\" : obs_grafo}\n",
    "\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        recompensa = 0\n",
    "        info = {}\n",
    "        self.steps += 1\n",
    "        \n",
    "        tipo = action[\"tipo\"]\n",
    "        destino = action[\"destino\"]\n",
    "\n",
    "        if tipo == 1:\n",
    "            recompensa += self._recogida_basura()\n",
    "        elif tipo == 0:\n",
    "            if destino in self.adjacencia[self.nodo_actual]:\n",
    "                # Cambio de nodo del camion\n",
    "                self.nodo_anterior = self.nodo_actual\n",
    "                self.nodos_indice[self.nodo_actual][\"posicion_camion\"] = 0\n",
    "                self.nodo_actual = destino\n",
    "                self.nodos_indice[self.nodo_actual][\"posicion_camion\"] = 1\n",
    "\n",
    "                recompensa += self._recorrido_camion()\n",
    "            else:\n",
    "                recompensa += -1\n",
    "        else: \n",
    "            recompensa += -1\n",
    "\n",
    "        terminado = False\n",
    "        truncado = False\n",
    "\n",
    "        # Condiciones finalización\n",
    "        # Terminado\n",
    "        if self.carga_camion >= self.capacidad_camion:\n",
    "            terminado = True\n",
    "        if self.nodo_actual == self.nodo_inicial and self.steps > 1:\n",
    "            terminado = True\n",
    "        \n",
    "        # Truncado\n",
    "        if self.steps >= self.steps_maximo:\n",
    "            truncado = True\n",
    "\n",
    "        # Recompensa final\n",
    "        if terminado or truncado:\n",
    "            recompensa += self._recompensa_final()\n",
    "\n",
    "        obs = self._obtener_observacion()\n",
    "        info = {\"mascara\": self._mascara_acciones()} if self.mascara else {}\n",
    "        return obs, recompensa, terminado, truncado, info\n",
    "    \n",
    "\n",
    "\n",
    "    def _recogida_basura(self):\n",
    "        recompensa = 0\n",
    "        nodo = self.nodos_indice[self.nodo_actual]\n",
    "        if nodo[\"contenedor\"] == 1 and nodo[\"llenado\"] > 0:\n",
    "            basura_disponible = nodo[\"llenado\"] * nodo[\"capacidad_contenedor\"]\n",
    "            self.carga_camion += basura_disponible\n",
    "\n",
    "            carga_camion_norm = min(1.0, self.carga_camion / self.capacidad_camion)\n",
    "\n",
    "            nodo[\"llenado\"] = 0 \n",
    "\n",
    "            for n in self.nodos_indice.values():\n",
    "                n[\"llenado_camion\"] = carga_camion_norm\n",
    "            \n",
    "            # Tiempo recogida \n",
    "            self.tiempo_total += 30 #sec, tiempo aprox recogida (cambiarlo a variable)\n",
    "\n",
    "            # Recompensas \n",
    "            recompensa = (basura_disponible / nodo[\"capacidad_contenedor\"]) * 2  # 1 factor arbitrario (recompensa inicial y sencilla) (si es menor al 50/70%, añadir mini penalización)\n",
    "            return recompensa\n",
    "        \n",
    "        elif nodo[\"contenedor\"] == 1 and nodo[\"llenado\"] == 0:\n",
    "            recompensa = 0\n",
    "            return recompensa\n",
    "\n",
    "        else:\n",
    "            recompensa = -1\n",
    "            return recompensa\n",
    "\n",
    "\n",
    "    def _recorrido_camion(self):\n",
    "        recompensa = 0\n",
    "\n",
    "        # Recompensas por tiempo recorrido y distancia recorrida\n",
    "\n",
    "        return recompensa\n",
    "\n",
    "\n",
    "\n",
    "    def _recompensa_final(self):\n",
    "        recompensa = 0\n",
    "\n",
    "        # Añadir recompensas y penalizaciones\n",
    "\n",
    "        return recompensa\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        print(f\"Nodo actual: {self.nodo_actual} | Carga camión: {self.carga_camion:.2f} kg | Step: {self.steps}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #def _get_accessible_nodes(self):\n",
    "    #        return self.adjacencia[self.nodo_actual]\n",
    "    \n",
    "\n",
    "\n",
    "    def _mascara_acciones(self):\n",
    "        mascara_tipo = np.array([True, True], dtype=bool)  \n",
    "        mascara_destino = np.zeros(len(self.nodos_indice), dtype=bool)\n",
    "\n",
    "        adjacentes = self._nodos_adjacentes()[self.nodo_actual]\n",
    "\n",
    "    # Excluir volver al nodo anterior, salvo callejón sin salida\n",
    "        if self.nodo_anterior is not None:\n",
    "            vecinos_validos = [v for v in adjacentes if v != self.nodo_anterior]\n",
    "            if len(vecinos_validos) == 0:\n",
    "                # caso callejón sin salida → permitimos volver\n",
    "                vecinos_validos = [self.nodo_anterior]\n",
    "        else:\n",
    "            vecinos_validos = adjacentes\n",
    "\n",
    "        mascara_destino[vecinos_validos] = True\n",
    "\n",
    "        nodo = self.nodos_indice[self.nodo_actual]\n",
    "        if not (nodo[\"contenedor\"] == 1 and nodo[\"llenado\"] > 0):\n",
    "            mascara_tipo[0] = False\n",
    "\n",
    "        return {\n",
    "            \"mascara_tipo\": mascara_tipo,\n",
    "            \"mascara_destino\": mascara_destino,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f810dda",
   "metadata": {},
   "source": [
    "Codigo para probar comportamiento entorno con agente aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agente_aleatorio(env, max_steps=20):\n",
    "    obs, info = env.reset()\n",
    "    terminated, truncated = False, False\n",
    "    contenedores_visitados = 0\n",
    "    recompensa_acumulada = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        print(f\"\\n--- Step {step + 1} ---\")\n",
    "        print(f\"Observación: {obs['simple']}\")\n",
    "        print(f\"Info: {info}\")\n",
    "\n",
    "        nodo_tiene_contenedor = obs[\"simple\"][\"contenedor\"] == 1\n",
    "        lleno_contenedor = obs[\"simple\"][\"llenado_contenedor\"] > 0\n",
    "\n",
    "        if info[\"mascara\"][\"mascara_tipo\"][0]:\n",
    "            # 100% probabilidad de recoger, 0% de moverse\n",
    "            contenedores_visitados += 1\n",
    "            if random.random() <= 1.0:\n",
    "                action = {\"tipo\": 1, \"destino\": 0}\n",
    "            else:\n",
    "                posibles = np.where(info[\"mascara\"][\"mascara_destino\"])[0]\n",
    "                destino = int(random.choice(posibles)) if len(posibles) > 0 else 0\n",
    "                action = {\"tipo\": 0, \"destino\": destino}\n",
    "        else:\n",
    "            # Nodo sin contenedor o contenedor vacío → siempre moverse\n",
    "            posibles = np.where(info[\"mascara\"][\"mascara_destino\"])[0]\n",
    "            destino = int(random.choice(posibles)) if len(posibles) > 0 else 0\n",
    "            action = {\"tipo\": 0, \"destino\": destino}\n",
    "\n",
    "        print(f\"Acción elegida: {action}\")\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        print(terminated)\n",
    "        print(truncated)\n",
    "        print(f\"Recompensa: {reward}\")\n",
    "        recompensa_acumulada += reward\n",
    "        env.render()\n",
    "\n",
    "        if terminated or truncated:\n",
    "            print(\"Episodio terminado.\")\n",
    "            print(f\"Contenedores_visitados = {contenedores_visitados}\")\n",
    "            print(f\"Recompensa acumulada = {recompensa_acumulada}\")\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
